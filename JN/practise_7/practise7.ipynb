{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f205ad78-17bc-480f-ab22-02f457608107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "526f27fc-7c45-4e35-a3da-813031d3bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cd1caed-5f2c-45de-9d7c-a1544a2d6796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', ',', 'My', 'name', 'is', 'Nikita', 'Malik.Iam', 'from', 'Haryana', 'but', 'living', 'in', 'gujarat', 'from', 'last', '10', 'years', '.', 'I', 'love', 'to', 'eat', 'delicious', 'food', '.']\n",
      "['Hi,My name is Nikita Malik.Iam from Haryana but living in gujarat from last 10 years.', 'I love to eat delicious food.']\n"
     ]
    }
   ],
   "source": [
    "corpus=\"Hi,My name is Nikita Malik.Iam from Haryana but living in gujarat from last 10 years. I love to eat delicious food.\"\n",
    "print(word_tokenize(corpus))\n",
    "print(sent_tokenize(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08eb66e2-3af1-45cb-a4ff-49b476e6ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cf96c08-040e-4bf3-acef-fb34ed840173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi', 'NNP'), (',', ','), ('My', 'NNP'), ('name', 'NN'), ('is', 'VBZ'), ('Nikita', 'NNP'), ('Malik.Iam', 'NNP'), ('from', 'IN'), ('Haryana', 'NNP'), ('but', 'CC'), ('living', 'VBG'), ('in', 'IN'), ('gujarat', 'NN'), ('from', 'IN'), ('last', 'JJ'), ('10', 'CD'), ('years', 'NNS'), ('.', '.'), ('I', 'PRP'), ('love', 'VBP'), ('to', 'TO'), ('eat', 'VB'), ('delicious', 'JJ'), ('food', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tokens=word_tokenize(corpus)\n",
    "print(pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf625478-899b-4fac-8784-1b835615405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7fb9ee6-be46-4fe2-8211-abe5eb1b2c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a901ede-96af-4c23-893a-7fac423f66ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', ',', 'My', 'name', 'Nikita', 'Malik.Iam', 'Haryana', 'living', 'gujarat', 'last', '10', 'years', '.', 'I', 'love', 'eat', 'delicious', 'food', '.']\n"
     ]
    }
   ],
   "source": [
    "clean=[]\n",
    "for i in tokens:\n",
    "    if(i not in stop_words):\n",
    "        clean.append(i)\n",
    "print(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "347c7632-b19c-497a-b7e2-40a89225846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0488ddfc-fc89-4b95-b53b-78aca1bc1751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', ',', 'my', 'name', 'nikita', 'malik.iam', 'haryana', 'live', 'gujarat', 'last', '10', 'year', '.', 'i', 'love', 'eat', 'delici', 'food', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer=PorterStemmer()\n",
    "stem_tokens=[]\n",
    "for i in clean:\n",
    "    st=stemmer.stem(i)\n",
    "    stem_tokens.append(st)\n",
    "print(stem_tokens)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f2debac-cee8-4f18-807e-c1f787b11f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ad206fe-bb58-4e1a-aa9f-7599a94b3945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', ',', 'My', 'name', 'Nikita', 'Malik.Iam', 'Haryana', 'living', 'gujarat', 'last', '10', 'year', '.', 'I', 'love', 'eat', 'delicious', 'food', '.']\n"
     ]
    }
   ],
   "source": [
    "lemma=WordNetLemmatizer()\n",
    "lem_tokens=[]\n",
    "for i in clean:\n",
    "    lem=lemma.lemmatize(i)\n",
    "    lem_tokens.append(lem)\n",
    "print(lem_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2e1706e-1099-436f-90d5-939fed11a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e4d715d-ecbd-467b-986b-7d8e51724308",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9bcfbd1-2cdb-48c4-9f50-96331b38bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Sachin was the GOAT of the previous generation\",\n",
    "    \"Virat is the GOAT of the this generation\",\n",
    "    \"Shubman will be the GOAT of the next generation\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23fb39c8-1511-4e4b-9a8f-0cb370c5bbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sachin': 7,\n",
       " 'was': 12,\n",
       " 'the': 9,\n",
       " 'goat': 2,\n",
       " 'of': 5,\n",
       " 'previous': 6,\n",
       " 'generation': 1,\n",
       " 'virat': 11,\n",
       " 'is': 3,\n",
       " 'this': 10,\n",
       " 'shubman': 8,\n",
       " 'will': 13,\n",
       " 'be': 0,\n",
       " 'next': 4}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix=v.fit(corpus)\n",
    "matrix.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a9f9bf1-c2c0-45b0-b9ee-ff406b69e760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 12)\t0.4286758743128819\n",
      "  (0, 9)\t0.5063657539459899\n",
      "  (0, 7)\t0.4286758743128819\n",
      "  (0, 6)\t0.4286758743128819\n",
      "  (0, 5)\t0.25318287697299496\n",
      "  (0, 2)\t0.25318287697299496\n",
      "  (0, 1)\t0.25318287697299496\n",
      "  (1, 11)\t0.4286758743128819\n",
      "  (1, 10)\t0.4286758743128819\n",
      "  (1, 9)\t0.5063657539459899\n",
      "  (1, 5)\t0.25318287697299496\n",
      "  (1, 3)\t0.4286758743128819\n",
      "  (1, 2)\t0.25318287697299496\n",
      "  (1, 1)\t0.25318287697299496\n",
      "  (2, 13)\t0.39400039808922477\n",
      "  (2, 9)\t0.4654059642457353\n",
      "  (2, 8)\t0.39400039808922477\n",
      "  (2, 5)\t0.23270298212286766\n",
      "  (2, 4)\t0.39400039808922477\n",
      "  (2, 2)\t0.23270298212286766\n",
      "  (2, 1)\t0.23270298212286766\n",
      "  (2, 0)\t0.39400039808922477\n"
     ]
    }
   ],
   "source": [
    "m=v.transform(corpus)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f915e112-50fd-4405-83e1-4792346147d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.25318288 0.25318288 0.         0.         0.25318288\n",
      "  0.42867587 0.42867587 0.         0.50636575 0.         0.\n",
      "  0.42867587 0.        ]\n",
      " [0.         0.25318288 0.25318288 0.42867587 0.         0.25318288\n",
      "  0.         0.         0.         0.50636575 0.42867587 0.42867587\n",
      "  0.         0.        ]\n",
      " [0.3940004  0.23270298 0.23270298 0.         0.3940004  0.23270298\n",
      "  0.         0.         0.3940004  0.46540596 0.         0.\n",
      "  0.         0.3940004 ]]\n"
     ]
    }
   ],
   "source": [
    "tidf_matrix=v.fit_transform(corpus)\n",
    "print(tidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b644b-105b-4197-8cdc-1f094815873c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
